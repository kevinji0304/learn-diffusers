{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Environment and Dependencies\n",
    "Install and import required libraries including diffusers, torch, datasets, and transformers. Setup training device (CPU/GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/diffusers-env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "# pip install diffusers torch datasets transformers\n",
    "\n",
    "# Import required libraries\n",
    "import torch\n",
    "from diffusers import DDPMPipeline, DDPMScheduler, DDPMPipeline\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Setup training device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Custom Dataset\n",
    "Load and preprocess custom images, create a custom dataset class, and set up the data loader for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images loaded: 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Create data loader\u001b[39;00m\n\u001b[1;32m     35\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m\n\u001b[0;32m---> 36\u001b[0m data_loader \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Display the number of images loaded\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/diffusers-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:376\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[0;32m--> 376\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    378\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/diffusers-env/lib/python3.10/site-packages/torch/utils/data/sampler.py:164\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    166\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# Define a custom dataset class\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = [os.path.join(image_dir, img) for img in os.listdir(image_dir) if img.endswith(('png', 'jpg', 'jpeg'))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Load custom dataset\n",
    "image_dir = '/users/jiyunkai/Documents/Photo/20240803_NIKONZFC'  # Replace with the path to your image directory\n",
    "dataset = CustomImageDataset(image_dir=image_dir, transform=transform)\n",
    "print(f\"Number of images loaded: {len(dataset)}\")\n",
    "# Create data loader\n",
    "batch_size = 16\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "# Display the number of images loaded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define DDPM Model Architecture\n",
    "Configure the DDPM model architecture using UNet2DModel and set hyperparameters like image size, timesteps, and batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import UNet2DModel\n",
    "\n",
    "# Define DDPM model architecture\n",
    "model = UNet2DModel(\n",
    "    sample_size=256,  # the target image size\n",
    "    in_channels=3,    # number of input channels (3 for RGB images)\n",
    "    out_channels=3,   # number of output channels\n",
    "    layers_per_block=2,  # number of layers per block\n",
    "    block_out_channels=(64, 128, 256, 512),  # number of output channels for each block\n",
    "    down_block_types=(\"DownBlock2D\", \"DownBlock2D\", \"DownBlock2D\", \"AttnDownBlock2D\"),  # types of down blocks\n",
    "    up_block_types=(\"UpBlock2D\", \"UpBlock2D\", \"UpBlock2D\", \"AttnUpBlock2D\")  # types of up blocks\n",
    ")\n",
    "\n",
    "# Set hyperparameters\n",
    "num_timesteps = 1000  # number of timesteps for the diffusion process\n",
    "learning_rate = 1e-4  # learning rate for the optimizer\n",
    "num_epochs = 10  # number of training epochs\n",
    "\n",
    "# Move model to the training device\n",
    "model.to(device)\n",
    "\n",
    "# Print model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Training Pipeline\n",
    "Set up the DDPMPipeline for training, including noise scheduler and optimizer configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the noise scheduler\n",
    "noise_scheduler = DDPMScheduler(num_train_timesteps=num_timesteps)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for step, batch in enumerate(data_loader):\n",
    "        # Move batch to the training device\n",
    "        batch = batch.to(device)\n",
    "        \n",
    "        # Sample noise\n",
    "        noise = torch.randn(batch.shape).to(device)\n",
    "        \n",
    "        # Sample a random timestep for each image\n",
    "        timesteps = torch.randint(0, num_timesteps, (batch_size,), device=device).long()\n",
    "        \n",
    "        # Add noise to the images according to the noise scheduler\n",
    "        noisy_images = noise_scheduler.add_noise(batch, noise, timesteps)\n",
    "        \n",
    "        # Predict the noise residual\n",
    "        noise_pred = model(noisy_images, timesteps).sample\n",
    "        \n",
    "        # Calculate the loss\n",
    "        loss = torch.nn.functional.mse_loss(noise_pred, noise)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print loss every 100 steps\n",
    "        if step % 100 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Step {step}/{len(data_loader)}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "Implement the training loop with forward pass, loss calculation, and backward propagation. Include progress tracking and model checkpointing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop with progress tracking and model checkpointing\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for step, batch in enumerate(data_loader):\n",
    "        # Move batch to the training device\n",
    "        batch = batch.to(device)\n",
    "        \n",
    "        # Sample noise\n",
    "        noise = torch.randn(batch.shape).to(device)\n",
    "        \n",
    "        # Sample a random timestep for each image\n",
    "        timesteps = torch.randint(0, num_timesteps, (batch_size,), device=device).long()\n",
    "        \n",
    "        # Add noise to the images according to the noise scheduler\n",
    "        noisy_images = noise_scheduler.add_noise(batch, noise, timesteps)\n",
    "        \n",
    "        # Predict the noise residual\n",
    "        noise_pred = model(noisy_images, timesteps).sample\n",
    "        \n",
    "        # Calculate the loss\n",
    "        loss = torch.nn.functional.mse_loss(noise_pred, noise)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate loss\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        # Print loss every 100 steps\n",
    "        if step % 100 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Step {step}/{len(data_loader)}, Loss: {loss.item()}\")\n",
    "    \n",
    "    # Calculate average loss for the epoch\n",
    "    avg_epoch_loss = epoch_loss / len(data_loader)\n",
    "    print(f\"Epoch {epoch+1} completed. Average Loss: {avg_epoch_loss}\")\n",
    "    \n",
    "    # Save model checkpoint\n",
    "    checkpoint_path = f\"ddpm_epoch_{epoch+1}.pth\"\n",
    "    torch.save(model.state_dict(), checkpoint_path)\n",
    "    print(f\"Model checkpoint saved at {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and Test Model\n",
    "Save the trained model and demonstrate how to generate new images using the custom-trained pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final trained model\n",
    "final_model_path = \"ddpm_final.pth\"\n",
    "torch.save(model.state_dict(), final_model_path)\n",
    "print(f\"Final model saved at {final_model_path}\")\n",
    "\n",
    "# Load the trained model for inference\n",
    "model.load_state_dict(torch.load(final_model_path))\n",
    "model.eval()\n",
    "\n",
    "# Define a function to generate new images\n",
    "def generate_images(model, num_images=1, num_inference_steps=120):\n",
    "    pipeline = DDPMPipeline(unet=model, scheduler=noise_scheduler)\n",
    "    pipeline.to(device)\n",
    "    generated_images = []\n",
    "    for _ in range(num_images):\n",
    "        image = pipeline(num_inference_steps=num_inference_steps).images[0]\n",
    "        generated_images.append(image)\n",
    "    return generated_images\n",
    "\n",
    "# Generate and display new images\n",
    "num_images_to_generate = 5\n",
    "generated_images = generate_images(model, num_images=num_images_to_generate)\n",
    "\n",
    "# Display the generated images\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, num_images_to_generate, figsize=(15, 5))\n",
    "for i, img in enumerate(generated_images):\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusers-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
